Tau DQM instructions for submitting condor jobs

Again, double-check that your globaltags are correct.

Since we want to use the entire file now instead of just ten events, 
run this command to generate the .py file of step2 again, except this command 
uses -n -1 (all events) and --no-exec, so it only generates the .py file 
without executing the command.

cmsDriver.py step2 -s RAW2DIGI,L1Reco,RECO,DQM --eventcontent DQM \
--datatier DQMIO --conditions 124X_dataRun3_v9 --era Run3 \
--geometry DB:Extended --process reRECO -n -1 --data \
--filein /store/data/Run2022D/Muon/RAW/v1/000/357/612/00000/000f3d07-0cc7-4742-862b-468f64f583e2.root --no_exec

Next, make sure you have enough space in eos. I use this command to check my space

du -h /eos/user/b/ballmond/

I think everyone starts with 1Terabyte of storage, and I'm using 16Gigabytes currently. 
Usually it's not the output from step2 that we have to worry about, but the files generated
in your home directory by condor. You can check your the amount of space you have in afs
with the same command, just cd to the top of your directory (i.e. where you are at login)
du -h | tail -n 1 

At the time of writing, I was using 2G/10G available.
From experience, I know that I can submit about 200 Files without running out of space. 
However, it would really be better to know how to do this more exactly, or, 
even better, be able to use the entire dataset without restrictions like this.


We need to make a new directory in /eos for output, something like

mkdir /eos/user/$letter$/$username$/DQM2022Step2FromRaw357612

Before making condor jobs, go to the /src/ directory of your CMSSW release and 
that the list of files you want to submit is in the same directory. 
Mine looks like this (we made this list of files in the first step, I 
had a file for each available run but deleted all the ones I'm not using).

[ballmond@lxplus734 src]$ ls
DQMOffline  HLTriggerOffline  ResourcesForTemporaryTauDQM  SimG4Core   cmsCondorStep2toStep3.py           step2_RAW2DIGI_L1Reco_RECO_DQM.root
HLTrigger   L1Trigger         Run357612.txt                SimTracker  step2_RAW2DIGI_L1Reco_RECO_DQM.py

The condor command to submit create the jobs for me is
python3 cmsCondorStep2toStep3.py step2_RAW2DIGI_L1Reco_RECO_DQM.py \
/afs/cern.ch/user/b/ballmond/public/CMSSW_12_4_0/src \
/eos/user/b/ballmond/2022DQMStep2FromRAW357612/ \
Run357612.txt -n 1 -q workday

For you, you need to customise the third and fourth arguments to be your current working directory and output directory on eos. 

It will take some time for the jobs to be generated. 
Once they have been generated, submit them with the command
./sub_total.jobb

It will take quite some time (several hours) to generate all the output, but some may be available early.
You can periodically check simply by ls-ing your output directory and 
also by checking the status of your condor jobs like so:

[ballmond@lxplus734 src]$ condor_q
-- Schedd: bigbird14.cern.ch : <137.138.44.75:9618?... @ 08/17/22 21:07:46
OWNER    BATCH_NAME     SUBMITTED   DONE   RUN    IDLE  TOTAL JOB_IDS
ballmond ID: 9674162   8/17 21:05      _      _    203    203 9674162.0-202

Once you have output multiple output files in your output directory on eos, 
you can run step3 with the following command and one additional change.

cmsDriver.py step3 -s HARVESTING:dqmHarvesting --harvesting AtRunEnd --conditions 124X_dataRun3_v9\
--era Run3  --geometry DB:Extended --scenario pp  --filein file:step2_RAW2DIGI_L1Reco_RECO_DQM.root\
--filetype DQM  -n -1 --data --no_exec

Inside the step3_HARVESTING.py file just generated, change the Input source from this

# Input source
process.source = cms.Source("DQMRootSource",
    fileNames = cms.untracked.vstring('file:step2_RAW2DIGI_L1Reco_RECO_DQM.root')
)

into this 
(where you use your own output from your own eos directory, 
right now i'm using a dummy directory with old output)

# Input source
process.source = cms.Source("DQMRootSource",
    fileNames = cms.untracked.vstring(
    'file:/eos/user/b/ballmond/STEAMDQMStep2/step2_RAW2DIGI_L1Reco_RECO_DQM_81.root',
    'file:/eos/user/b/ballmond/STEAMDQMStep2/step2_RAW2DIGI_L1Reco_RECO_DQM_83.root',
    'file:/eos/user/b/ballmond/STEAMDQMStep2/step2_RAW2DIGI_L1Reco_RECO_DQM_84.root',
    'file:/eos/user/b/ballmond/STEAMDQMStep2/step2_RAW2DIGI_L1Reco_RECO_DQM_85.root',
    'file:/eos/user/b/ballmond/STEAMDQMStep2/step2_RAW2DIGI_L1Reco_RECO_DQM_86.root',
    'file:/eos/user/b/ballmond/STEAMDQMStep2/step2_RAW2DIGI_L1Reco_RECO_DQM_87.root',
    'file:/eos/user/b/ballmond/STEAMDQMStep2/step2_RAW2DIGI_L1Reco_RECO_DQM_92.root',
    'file:/eos/user/b/ballmond/STEAMDQMStep2/step2_RAW2DIGI_L1Reco_RECO_DQM_94.root',
    'file:/eos/user/b/ballmond/STEAMDQMStep2/step2_RAW2DIGI_L1Reco_RECO_DQM_98.root',
    'file:/eos/user/b/ballmond/STEAMDQMStep2/step2_RAW2DIGI_L1Reco_RECO_DQM_99.root',
  )
)

You can obtain file names like this with the following command:
find /eos/user/b/ballmond/2022DQMStep2FromRAW357612/ >> files_to_use.tx

Finally, run step3 like so:
cmsRun step3_HARVESTING.py

It could take some time, but it will eventually generate a DQM file which you can investigate with TBrowser again.

That should be everything!

